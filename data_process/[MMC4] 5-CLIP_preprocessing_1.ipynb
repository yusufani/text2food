{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7jqJyS3vntM"
      },
      "outputs": [],
      "source": [
        "PART = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjUHBb5Sv8z3",
        "outputId": "e0cb7787-f06c-4ae3-ead3-5ee9558384e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul  3 14:08:37 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    51W / 400W |  13199MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(f'/home/daryna-lab-course/text2food/data/tringas_any_class_higher_95_batch_im_download-div-{PART}.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "37V3J2d2wCLm",
        "outputId": "b5c5fb66-db00-43e3-c4b9-95628d94a650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  \\\n",
              "0                 0             0           0   \n",
              "1                 1             3           3   \n",
              "2                 2             7           7   \n",
              "3                 3             8           8   \n",
              "4                 4             9           9   \n",
              "...             ...           ...         ...   \n",
              "49373         49373        108449      108449   \n",
              "49374         49374        108454      108454   \n",
              "49375         49375        108455      108455   \n",
              "49376         49376        108456      108456   \n",
              "49377         49377        108461      108461   \n",
              "\n",
              "                                              words  \\\n",
              "0                                          ['meal']   \n",
              "1                               ['basmati', 'rice']   \n",
              "2                                      ['gumballs']   \n",
              "3                                        ['leaves']   \n",
              "4                           ['coriander', 'flavor']   \n",
              "...                                             ...   \n",
              "49373                                      ['malt']   \n",
              "49374  ['chocolate', 'peanut', 'butter', 'recipes']   \n",
              "49375                                 ['clafoutis']   \n",
              "49376                                      ['rice']   \n",
              "49377                                      ['feed']   \n",
              "\n",
              "                                            matched_text  \\\n",
              "0      In Kardamyli three years ago, once I'd discove...   \n",
              "1         DO NOT use basmati rice to prepare chitrannam.   \n",
              "2      Gumballs like these are great every day or for...   \n",
              "3      ENGAGING ONE-YEAR-ONLY DESIGN - The 1996 One-O...   \n",
              "4      My first couple of bites took me aback, becaus...   \n",
              "...                                                  ...   \n",
              "49373                A NAS Malt of Jura; good and cheap!   \n",
              "49374  Instead of letting them derail my progress I'v...   \n",
              "49375  If you are new to this site, then you wouldn't...   \n",
              "49376  Rice terraces in Northern are slopes claimed f...   \n",
              "49377  Download your FREE Edna's Feed Sacks PATTERN H...   \n",
              "\n",
              "                                                 raw_url         image_name  \\\n",
              "0      https://thesinglegourmetandtraveller.files.wor...   5729e94a79ae.jpg   \n",
              "1      https://2.bp.blogspot.com/-spgP6aiCi9U/UBVnSvR...   2465d452ab65.jpg   \n",
              "2      https://www.candymachines.com/images/bulk_gumb...   b2a8e8cf7a6d.jpg   \n",
              "3      https://www.govmint.com/media/catalog/product/...   f79a157be2fa.jpg   \n",
              "4      https://img.city-cost.com/800x800/40eaed8df91c...  8a3f66a1bba9.jpeg   \n",
              "...                                                  ...                ...   \n",
              "49373  https://static.whiskybase.com/storage/whiskies...   a21ba30f7fa5.jpg   \n",
              "49374  https://mycrazygoodlife.com/wp-content/uploads...   614715119bc7.jpg   \n",
              "49375  https://clborah.files.wordpress.com/2016/04/cl...   a926e8aa4e9c.jpg   \n",
              "49376  https://4.bp.blogspot.com/-qpxJydB3EwM/Wqzk2MF...   b4cde77aaedb.jpg   \n",
              "49377  https://quiltinaday.com/images-products/2019/D...   e361e86ff5e4.jpg   \n",
              "\n",
              "                                                  labels  \\\n",
              "0      ['describing food', 'describing beverages', 'n...   \n",
              "1      ['describing food', 'describing beverages', 'n...   \n",
              "2      ['describing food', 'describing beverages', 'n...   \n",
              "3      ['describing food', 'not describing beverages'...   \n",
              "4      ['describing food', 'not describing beverages'...   \n",
              "...                                                  ...   \n",
              "49373  ['describing food', 'describing beverages', 'n...   \n",
              "49374  ['describing food', 'not describing beverages'...   \n",
              "49375  ['describing food', 'describing beverages', 'n...   \n",
              "49376  ['describing food', 'not describing beverages'...   \n",
              "49377  ['describing food', 'not describing beverages'...   \n",
              "\n",
              "                                                  scores  \\\n",
              "0      ['0.9097504615783691', '0.04694497212767601', ...   \n",
              "1      ['0.8960762619972229', '0.0688355565071106', '...   \n",
              "2      ['0.8749205470085144', '0.08553430438041687', ...   \n",
              "3      ['0.8120938539505005', '0.08863692730665207', ...   \n",
              "4      ['0.9168951511383057', '0.03275753930211067', ...   \n",
              "...                                                  ...   \n",
              "49373  ['0.4994945526123047', '0.4704190790653229', '...   \n",
              "49374  ['0.9306913614273071', '0.036240167915821075',...   \n",
              "49375  ['0.7788848280906677', '0.17939694225788116', ...   \n",
              "49376  ['0.9370181560516357', '0.035220205783843994',...   \n",
              "49377  ['0.7951399683952332', '0.10342413932085037', ...   \n",
              "\n",
              "                                              image_path  \n",
              "0      /content/drive/MyDrive/text2food/dataset/befor...  \n",
              "1      /content/drive/MyDrive/text2food/dataset/befor...  \n",
              "2      /content/drive/MyDrive/text2food/dataset/befor...  \n",
              "3      /content/drive/MyDrive/text2food/dataset/befor...  \n",
              "4      /content/drive/MyDrive/text2food/dataset/befor...  \n",
              "...                                                  ...  \n",
              "49373  /content/drive/MyDrive/text2food/dataset/befor...  \n",
              "49374  /content/drive/MyDrive/text2food/dataset/befor...  \n",
              "49375  /content/drive/MyDrive/text2food/dataset/befor...  \n",
              "49376  /content/drive/MyDrive/text2food/dataset/befor...  \n",
              "49377  /content/drive/MyDrive/text2food/dataset/befor...  \n",
              "\n",
              "[49378 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ac67d59-618d-471f-8fef-ad31ad39841a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.2</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>words</th>\n",
              "      <th>matched_text</th>\n",
              "      <th>raw_url</th>\n",
              "      <th>image_name</th>\n",
              "      <th>labels</th>\n",
              "      <th>scores</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['meal']</td>\n",
              "      <td>In Kardamyli three years ago, once I'd discove...</td>\n",
              "      <td>https://thesinglegourmetandtraveller.files.wor...</td>\n",
              "      <td>5729e94a79ae.jpg</td>\n",
              "      <td>['describing food', 'describing beverages', 'n...</td>\n",
              "      <td>['0.9097504615783691', '0.04694497212767601', ...</td>\n",
              "      <td>/content/drive/MyDrive/text2food/dataset/befor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>['basmati', 'rice']</td>\n",
              "      <td>DO NOT use basmati rice to prepare chitrannam.</td>\n",
              "      <td>https://2.bp.blogspot.com/-spgP6aiCi9U/UBVnSvR...</td>\n",
              "      <td>2465d452ab65.jpg</td>\n",
              "      <td>['describing food', 'describing beverages', 'n...</td>\n",
              "      <td>['0.8960762619972229', '0.0688355565071106', '...</td>\n",
              "      <td>/content/drive/MyDrive/text2food/dataset/befor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>['gumballs']</td>\n",
              "      <td>Gumballs like these are great every day or for...</td>\n",
              "      <td>https://www.candymachines.com/images/bulk_gumb...</td>\n",
              "      <td>b2a8e8cf7a6d.jpg</td>\n",
              "      <td>['describing food', 'describing beverages', 'n...</td>\n",
              "      <td>['0.8749205470085144', '0.08553430438041687', ...</td>\n",
              "      <td>/content/drive/MyDrive/text2food/dataset/befor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>['leaves']</td>\n",
              "      <td>ENGAGING ONE-YEAR-ONLY DESIGN - The 1996 One-O...</td>\n",
              "      <td>https://www.govmint.com/media/catalog/product/...</td>\n",
              "      <td>f79a157be2fa.jpg</td>\n",
              "      <td>['describing food', 'not describing beverages'...</td>\n",
              "      <td>['0.8120938539505005', '0.08863692730665207', ...</td>\n",
              "      <td>/content/drive/MyDrive/text2food/dataset/befor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>['coriander', 'flavor']</td>\n",
              "      <td>My first couple of bites took me aback, becaus...</td>\n",
              "      <td>https://img.city-cost.com/800x800/40eaed8df91c...</td>\n",
              "      <td>8a3f66a1bba9.jpeg</td>\n",
              "      <td>['describing food', 'not describing beverages'...</td>\n",
              "      <td>['0.9168951511383057', '0.03275753930211067', ...</td>\n",
              "      <td>/content/drive/MyDrive/text2food/dataset/befor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49373</th>\n",
              "      <td>49373</td>\n",
              "      <td>108449</td>\n",
              "      <td>108449</td>\n",
              "      <td>['malt']</td>\n",
              "      <td>A NAS Malt of Jura; good and cheap!</td>\n",
              "      <td>https://static.whiskybase.com/storage/whiskies...</td>\n",
              "      <td>a21ba30f7fa5.jpg</td>\n",
              "      <td>['describing food', 'describing beverages', 'n...</td>\n",
              "      <td>['0.4994945526123047', '0.4704190790653229', '...</td>\n",
              "      <td>/content/drive/MyDrive/text2food/dataset/befor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49374</th>\n",
              "      <td>49374</td>\n",
              "      <td>108454</td>\n",
              "      <td>108454</td>\n",
              "      <td>['chocolate', 'peanut', 'butter', 'recipes']</td>\n",
              "      <td>Instead of letting them derail my progress I'v...</td>\n",
              "      <td>https://mycrazygoodlife.com/wp-content/uploads...</td>\n",
              "      <td>614715119bc7.jpg</td>\n",
              "      <td>['describing food', 'not describing beverages'...</td>\n",
              "      <td>['0.9306913614273071', '0.036240167915821075',...</td>\n",
              "      <td>/content/drive/MyDrive/text2food/dataset/befor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49375</th>\n",
              "      <td>49375</td>\n",
              "      <td>108455</td>\n",
              "      <td>108455</td>\n",
              "      <td>['clafoutis']</td>\n",
              "      <td>If you are new to this site, then you wouldn't...</td>\n",
              "      <td>https://clborah.files.wordpress.com/2016/04/cl...</td>\n",
              "      <td>a926e8aa4e9c.jpg</td>\n",
              "      <td>['describing food', 'describing beverages', 'n...</td>\n",
              "      <td>['0.7788848280906677', '0.17939694225788116', ...</td>\n",
              "      <td>/content/drive/MyDrive/text2food/dataset/befor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49376</th>\n",
              "      <td>49376</td>\n",
              "      <td>108456</td>\n",
              "      <td>108456</td>\n",
              "      <td>['rice']</td>\n",
              "      <td>Rice terraces in Northern are slopes claimed f...</td>\n",
              "      <td>https://4.bp.blogspot.com/-qpxJydB3EwM/Wqzk2MF...</td>\n",
              "      <td>b4cde77aaedb.jpg</td>\n",
              "      <td>['describing food', 'not describing beverages'...</td>\n",
              "      <td>['0.9370181560516357', '0.035220205783843994',...</td>\n",
              "      <td>/content/drive/MyDrive/text2food/dataset/befor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49377</th>\n",
              "      <td>49377</td>\n",
              "      <td>108461</td>\n",
              "      <td>108461</td>\n",
              "      <td>['feed']</td>\n",
              "      <td>Download your FREE Edna's Feed Sacks PATTERN H...</td>\n",
              "      <td>https://quiltinaday.com/images-products/2019/D...</td>\n",
              "      <td>e361e86ff5e4.jpg</td>\n",
              "      <td>['describing food', 'not describing beverages'...</td>\n",
              "      <td>['0.7951399683952332', '0.10342413932085037', ...</td>\n",
              "      <td>/content/drive/MyDrive/text2food/dataset/befor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49378 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ac67d59-618d-471f-8fef-ad31ad39841a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ac67d59-618d-471f-8fef-ad31ad39841a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ac67d59-618d-471f-8fef-ad31ad39841a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install open_clip_torch matplotlib\n",
        "import numpy as np\n",
        "import torch\n",
        "import open_clip\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from open_clip import tokenizer\n",
        "open_clip.list_pretrained()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model, _, preprocess = open_clip.create_model_and_transforms('ViT-L-14', pretrained='datacomp_xl_s13b_b90k',device=device)\n",
        "\n",
        "model.eval()\n",
        "context_length = model.context_length\n",
        "vocab_size = model.vocab_size\n",
        "\n",
        "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RkdYAyHvwsv",
        "outputId": "9fe5de70-a5c6-49cf-e8ae-03aaa7ae5123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: open_clip_torch in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.15.2+cu118)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2022.10.31)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (6.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.15.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.1.99)\n",
            "Requirement already satisfied: protobuf<4 in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (3.20.3)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.9.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->open_clip_torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->open_clip_torch) (16.0.6)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch) (0.2.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (6.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->open_clip_torch) (0.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->open_clip_torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->open_clip_torch) (1.3.0)\n",
            "Model parameters: 427,616,513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positives = [\n",
        "    'A close-up photo of food',\n",
        "    'A photo of food' , 'A photo of beverage' , 'A photo of breakfast' , 'A photo of lunch' , 'A photo of dinner' , 'A photo of snack' , 'A photo of Appetizer' , 'A photo of meal' ,\n",
        "      'A photo of nutritional meal' , 'A photo of a drink' ,\n",
        "             'A photo of traditional food',\n",
        "             'culinary',\n",
        "             'A photo of cooking']\n",
        "\n",
        "negatives = [\n",
        "     'Not A close-up photo of food',\n",
        "     'Not A photo of food' , 'Not A photo of beverage' , 'Not A photo of breakfast' , 'Not A photo of lunch' , 'Not A photo of dinner' , 'Not A photo of snack'  , 'Not A photo of Appetizer' , 'Not A photo of meal' ,\n",
        "     'Not A photo of nutritional meal' , 'Not A photo of a drink' ]\n",
        "\n",
        "#texts = positives + negatives\n",
        "texts = positives"
      ],
      "metadata": {
        "id": "Q-98ePmSv0Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_tokens = tokenizer.tokenize(texts).to(device)\n",
        "with torch.no_grad():\n",
        "      text_features = model.encode_text(text_tokens).float()\n",
        "text_features /= text_features.norm(dim=-1, keepdim=True)"
      ],
      "metadata": {
        "id": "5qjlTuy-EQJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = df[:10]"
      ],
      "metadata": {
        "id": "WGU_pohzW2_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "image_names= df.image_name.tolist()\n",
        "image_names = [f\"/home/daryna-lab-course/text2food/data/before_clip_1_2_3/before_clip_1_2_3/{i}\" for i in image_names][:10]\n",
        "#images = [Image.open(i) for i in tqdm(image_paths)]"
      ],
      "metadata": {
        "id": "qliVcM02mOW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "batch_size = 512\n",
        "results = []\n",
        "not_found = []\n",
        "for i in tqdm(range(0, len(image_names) , batch_size) , desc= 'processing' , total = (len(image_names)// batch_size) +1 ):\n",
        "  batch= image_names[i: i+batch_size]\n",
        "\n",
        "  images = []\n",
        "  for img in batch:\n",
        "      try:\n",
        "          images.append(Image.open(img))\n",
        "      except Exception as e:\n",
        "          not_found.append(img)  # Add problematic image to the error list\n",
        "\n",
        "\n",
        "  image_input = torch.tensor(np.stack([preprocess(i) for i in images])).to(device)\n",
        "  with torch.no_grad():\n",
        "    image_features = model.encode_image(image_input).float()\n",
        "  image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "  similarity_matrix = torch.mm(image_features, text_features.T)\n",
        "  for i in images:\n",
        "    i.close()\n",
        "  results.extend([{t:score.item() for t,score in zip(texts,i)} for i in similarity_matrix ])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXlBJ2-2EWTt",
        "outputId": "45e18b3c-2bda-4e8d-878f-d82b49cc8289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "processing: 100%|██████████| 97/97 [2:46:57<00:00, 103.27s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch.index('/content/drive/MyDrive/text2food/dataset/before_clip_1/c9d/c9d9154710f8.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYPYXOY8_n-N",
        "outputId": "f795d850-59f4-4dba-fe81-dadd12079355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch[296]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s1HKupN9BDh9",
        "outputId": "e2f87a60-a1e6-4ca6-dfc7-d2d7431aa2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/text2food/dataset/before_clip_1/c9d/c9d9154710f8.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#type(df['image_path'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5JcGT7JBpqo",
        "outputId": "4a92aab9-f8c5-4542-ffa5-ec591791f4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#len(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCIokRQFr6-Z",
        "outputId": "43a8710b-a31a-4a57-86cd-32b99a6448aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40152"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "UlHdYnYUtBB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/home/daryna-lab-course/text2food/data/clip_data.json', 'w') as f:\n",
        "    json.dump(results, f)"
      ],
      "metadata": {
        "id": "1zbHslzZsx28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/home/daryna-lab-course/text2food/data/deleted_images.txt', 'w') as f:\n",
        "    for line in not_found:\n",
        "        f.write(f\"{line}\\n\")"
      ],
      "metadata": {
        "id": "9FCP7Bp3ttJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(not_found)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkEIoL0guMIf",
        "outputId": "9a252e2b-fa48-402c-8e79-8615557963fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9226"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['image_clip_scores'] = results"
      ],
      "metadata": {
        "id": "kbadGso_Yl87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('/home/daryna-lab-course/text2food/data/tringas_any_class_higher_95_clip' , exist_ok=True)\n",
        "df.to_csv(f'/home/daryna-lab-course/text2food/data/tringas_any_class_higher_95_clip/tringas_any_class_higher_95_batch_clip-{PART}.csv')"
      ],
      "metadata": {
        "id": "iBDgVCrHrbcF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}